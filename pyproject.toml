[tool.poetry]
name = "optillm"
version = "0.1.0"
description = "Optimizing inference proxy for LLMs"
authors = ["Your Name <you@example.com>"]
license = "Apache 2.0"
readme = "README.md"
packages = [
    { include="optillm", from="src" },
]

[tool.poetry.scripts]
optillm-proxy = "optillm.proxy:main"

[tool.poetry.dependencies]
python = ">3.10,<4.0"
numpy = "^2.1.1"
networkx = "^3.3"
openai = "^1.47.1"
z3-solver = "^4.13.0.0"
aiohttp = "^3.10.5"
flask = "^3.0.3"
torch = "^2.4.1"
transformers = "^4.44.2"
azure-identity = "^1.18.0"


[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
